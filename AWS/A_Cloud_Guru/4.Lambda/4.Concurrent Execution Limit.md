# AWS Lambda Concurrent Execution Limits & Error Handling

## 1. Overview

AWS Lambda allows multiple function instances to run simultaneously. The default **concurrent execution limit** is **1,000 per AWS region** per account.

## 2. Concurrent Execution Limits

### ‚úÖ Types of Concurrency Limits

- **Regional Limit:** Default **1,000 concurrent executions** (can be increased via AWS Support).
- **Reserved Concurrency:** Limits the max number of concurrent executions for a function.
- **Provisioned Concurrency:** Keeps functions **warm** for **faster execution** without cold starts.

### üìà Scaling Behavior

- AWS Lambda can handle an **initial burst** of **500** instances.
- After that, it **scales by 500 instances per minute** until reaching the limit.

---

## 3. What Happens When Limit is Exceeded?

### ‚ö†Ô∏è Scenario 1: Too Many Concurrent Executions

- If **more than 1,000** requests arrive simultaneously, some requests will **fail**.

#### üî¥ Error Message & Status Code

```json
{
  "errorMessage": "Rate Exceeded",
  "statusCode": 429
}
```

### ‚ö†Ô∏è Scenario 2: Reserved Concurrency Limit Reached

- If a function has reserved concurrency set to 100 and 101 requests arrive, the 101st request fails.

#### üî¥ Error Message & Status Code

```json
{
  "errorMessage": "TooManyRequestsException: Rate exceeded for function",
  "statusCode": 429
}
```

### ‚ö†Ô∏è Scenario 3: Provisioned Concurrency Limit Reached

- If Provisioned Concurrency = 10 but 20 requests arrive, only 10 execute immediately.
- The remaining 10 may experience cold starts or fail if timeouts occur.

```json
{
  "errorMessage": "ProvisionedConcurrencyExceededException",
  "statusCode": 429
}
```

## 4. How to Monitor & Manage Concurrency?

### üìä Monitor Concurrency Usage

Use **AWS CloudWatch Metrics**:

- **`ConcurrentExecutions`** ‚Äì Tracks real-time concurrent executions.
- **`Throttles`** ‚Äì Shows the number of requests denied due to limits.

### ‚ö° Set Up Auto Scaling & Alerts

- Use **AWS Lambda Auto Scaling** with **DynamoDB, SQS, or EventBridge** to handle traffic spikes.
- Configure **CloudWatch Alarms** to notify when concurrency is near the limit.
- Use **Amazon EventBridge** to trigger workflows or reroute requests when concurrency thresholds are exceeded.

---

## 5. Best Practices to Avoid Errors

‚úÖ **Optimize Function Execution Time** ‚Äì Reduce execution duration to free up concurrency.  
‚úÖ **Use Reserved Concurrency** ‚Äì Set limits to prevent one function from consuming all resources.  
‚úÖ **Enable Provisioned Concurrency** ‚Äì Reduce cold starts for latency-sensitive apps.  
‚úÖ **Distribute Load** ‚Äì Use multiple functions, **SQS**, **EventBridge**, or event-driven architectures.

---

## 6. Summary Table

| **Scenario**                    | **Error Message**                                        | **HTTP Status Code**           | **Solution**                           |
| ------------------------------- | -------------------------------------------------------- | ------------------------------ | -------------------------------------- |
| Exceeding Regional Limit        | `"Rate Exceeded"`                                        | `429 TooManyRequestsException` | Increase limit, optimize function time |
| Hitting Reserved Concurrency    | `"TooManyRequestsException: Rate exceeded for function"` | `429 TooManyRequestsException` | Increase reserved concurrency          |
| Provisioned Concurrency Reached | `"ProvisionedConcurrencyExceededException"`              | `429 TooManyRequestsException` | Increase provisioned concurrency       |
